# 특성 선택

## 특성 선택

### 특성 선택이란?

**특성 선택(feature selection)**이란 모델 학습에 사용되는 여러 입력 변수(특성) 중에서 **중요한 특성만 선별**하는 과정이다.

* 모든 변수를 사용하는 것이 항상 좋은 것은 아님
* 불필요하거나 중복된 특성은 오히려 성능을 저하시킬 수 있음

#### 특성 선택의 목적

* 모델 성능 향상 (과적합 감소)
* 학습 시간 단축
* 모델 해석력 향상
* 데이터 수집 및 관리 비용 감소

### 특성 선택 vs 특성 추출

혼동하기 쉬운 개념이므로 먼저 구분한다.

* **특성 선택**

  * 기존 변수 중 일부를 선택
  * 변수의 의미가 유지됨
* **특성 추출**

  * 기존 변수를 변환하여 새로운 변수 생성
  * 예: PCA

## 필터(Filter) 방법

### 개념

**모델을 사용하지 않고** 데이터의 통계적 특성만으로 특성을 평가하는 방법이다. 각 특성을 **독립적으로** 평가한다.

### 주요 특징

* 계산 속도가 빠름
* 모델과 무관
* 변수 간 상호작용은 고려하지 못함

### 대표적인 필터 방법

#### (1) 분산 기반 선택

* 분산이 거의 없는 변수는 정보량이 적음
* 예: 대부분 값이 동일한 변수 제거

#### (2) 상관계수 기반 선택

* 입력 변수와 타깃 변수 간 상관관계 측정
* Pearson, Spearman, Kendall 등 활용 가능
* 절댓값이 큰 변수일수록 중요

#### (3) 통계적 검정

* 분류 문제

  * 카이제곱 검정
* 회귀 문제

  * F-test

### 필터 방법 예제

```python
from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(score_func=f_classif, k=3)
X_selected = selector.fit_transform(X, y)
```

## 래퍼(Wrapper) 방법

### 개념

**모델의 성능을 기준**으로 특성 조합을 평가하는 방법으로 특정 모델에 최적화된 특성 선택이 가능하다.

### 주요 특징

* 성능은 좋지만 계산 비용이 큼
* 모델에 종속적

### 대표적인 래퍼 방법

#### (1) 전진 선택 (Forward Selection)

* 특성이 없는 상태에서 시작
* 하나씩 추가하면서 성능 개선 여부 평가

#### (2) 후진 제거 (Backward Elimination)

* 모든 특성으로 시작
* 하나씩 제거하면서 성능 변화 확인

#### (3) 재귀적 특성 제거 (RFE)

* 모델 학습 → 중요도 낮은 특성 제거 반복

### 래퍼 방법 예제

```python
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
rfe = RFE(model, n_features_to_select=3)
X_selected = rfe.fit_transform(X, y)
```

## 3.2.5 임베디드(Embedded) 방법

### 개념

**모델 학습 과정 자체에** 특성 선택이 포함된 방법이다. 필터와 래퍼의 중간 성격을 가진다.

### 주요 특징

* 계산 효율과 성능의 균형
* 특정 모델에 내장된 방식

### 대표적인 임베디드 방법

#### (1) 정규화 기반 방법

* L1 정규화 (Lasso)

  * 중요하지 않은 특성의 계수를 0으로 만듦
* L2 정규화 (Ridge)

  * 계수 크기를 줄이지만 제거하지는 않음

#### (2) 트리 기반 모델

* 결정트리
* 랜덤 포레스트
* Gradient Boosting

→ 특성 중요도(feature importance) 제공

### 임베디드 방법 예제

```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X, y)

importances = model.feature_importances_
```

## 방법별 비교 정리

* **필터 방법**

  * 빠름
  * 모델 독립적
  * 상호작용 고려 어려움

* **래퍼 방법**

  * 성능 우수
  * 계산 비용 큼
  * 모델 의존적

* **임베디드 방법**

  * 효율과 성능의 균형
  * 특정 알고리즘에 종속

## 활용 전략

* 데이터가 크고 특성이 많을 때

  * 필터 → 임베디드 순서
* 모델 성능이 중요한 경우

  * 래퍼 또는 임베디드
* 해석이 중요한 경우

  * 필터 또는 Lasso 기반 접근
