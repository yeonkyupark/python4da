# 회귀 모델

## 회귀 모델 

### 회귀 모델

**회귀 모델**(Regression Models)은 입력 변수(X)와 **연속형 타깃 변수(y)** 사이의 관계를 학습하여 새로운 입력에 대한 **수치값을 예측**하는 모델이다.

* 예측 대상이 수치형
* 관계를 함수 형태로 모델링

### 회귀 vs 분류

* 회귀

  * 출력: 연속형 값
  * 예: 체중 예측, 매출 예측
* 분류

  * 출력: 범주
  * 예: 종 분류, 합격/불합격

## 선형 회귀 

### 기본 개념

선형 회귀(Linear Regression)는 입력 변수와 출력 변수 사이의 관계를 **선형 결합**으로 표현한다.

#### 수식 형태

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p + \varepsilon
$$

* $\beta$: 회귀 계수
* $\varepsilon$: 오차항

### 선형 회귀의 가정

* 선형성
* 독립성
* 등분산성
* 정규성 (오차)

현실 데이터에서는 **완벽히 만족하지 않는 경우가 많음**

### 선형 회귀 예제 

```{python}
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

df = sns.load_dataset("penguins").dropna()

X = df[["bill_length_mm", "bill_depth_mm", "flipper_length_mm"]]
y = df["body_mass_g"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model = LinearRegression()
model.fit(X_train, y_train)

model.coef_, model.intercept_
```

### 선형 회귀의 한계

* 다중공선성 문제
* 과적합 위험
* 변수 수가 많을수록 불안정

이를 해결하기 위한 방법이 **정규화 회귀**

## 정규화 개념

### 왜 정규화가 필요한가?
정규화(Regularization)가 필요한 이유는 다음과 같다.  

* 계수가 너무 커지는 것을 방지
* 불필요한 변수 영향 축소
* 과적합 감소

**손실 함수에 패널티 항을 추가**

### 일반적인 손실 함수 구조

$$
\text{Loss} = \text{오차} + \lambda \times \text{패널티}
$$

* $\lambda$: 규제 강도
* 값이 클수록 규제 강함

## Ridge 회귀 (L2 정규화)

### 개념

계수의 **제곱합(L2)**에 패널티 부여하여 모든 변수를 유지하되 계수 크기를 줄이는 방식이다.

### 특징

* 다중공선성 완화
* 변수 선택은 하지 않음
* 계수를 0에 가깝게 만듦

### Ridge 예제

```python
from sklearn.linear_model import Ridge

ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)

ridge.coef_
```

## Lasso 회귀 (L1 정규화)

### 개념
계수의 **절댓값 합(L1)**에 패널티 부여 일부 계수를 **0으로 만든다**.

### 특징

* 자동 변수 선택 효과
* 해석이 쉬움
* 변수 수가 많을 때 유리

### Lasso 예제

```python
from sklearn.linear_model import Lasso

lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)

lasso.coef_
```

## ElasticNet (L1 + L2)

### 개념
Ridge + Lasso의 혼합 방법으로 두 패널티의 장점 결합한 형태이다.


### 하이퍼파라미터

* alpha: 전체 규제 강도
* l1_ratio: L1 비율

### ElasticNet 예제

```python
from sklearn.linear_model import ElasticNet

elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)
elastic.fit(X_train, y_train)

elastic.coef_
```

## 회귀 모델 비교 요약

* **선형 회귀**

  * 기준 모델
  * 규제 없음
* **Ridge**

  * 안정적인 계수
  * 다중공선성 대응
* **Lasso**

  * 변수 선택
  * 해석 용이
* **ElasticNet**

  * 복합적인 상황에 적합

## 선택 가이드

* 변수 수 적고 해석 중요

  * 선형 회귀
* 변수 간 상관 높음

  * Ridge
* 변수 선택 필요

  * Lasso
* 고차원 데이터

  * ElasticNet

## 전처리 주의 사항

* 정규화 회귀는 **스케일에 민감**
* 반드시 **표준화 후 적용**

```python
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("model", Ridge(alpha=1.0))
])

pipe.fit(X_train, y_train)
```
회귀 모델은 연속형 예측의 기본이고 정규화는 과적합 방지의 핵심이다. 모델 선택보다 **전처리 + 하이퍼파라미터 튜닝**이 더 중요할 수 있다.

