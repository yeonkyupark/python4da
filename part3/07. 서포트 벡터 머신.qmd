# 서포트 벡터 머신

## SVM 개요

**서포트 벡터 머신(Support Vector Machine, SVM)** 은 클래스를 가장 잘 구분하는 **결정 경계(초평면)** 를 찾는 분류 모델이다.

핵심 아이디어는 단순하다.

* 클래스 간 **마진(margin)** 을 최대화
* 경계에 가장 가까운 데이터만 학습에 사용

이 “경계에 가장 가까운 데이터”를 **서포트 벡터**라고 부른다.

## 마진과 서포트 벡터

### 마진(Margin)

* 결정 경계와 가장 가까운 데이터 사이의 거리
* SVM은 **마진이 최대가 되도록** 경계를 찾는다

노이즈에 강하고 일반화 성능이 좋음

### 서포트 벡터

* 결정 경계를 결정하는 핵심 데이터
* 전체 데이터 중 **일부만 모델을 결정**

즉, SVM은

> “모든 데이터를 쓰지 않는다”

## 하드 마진 vs 소프트 마진

### 하드 마진

* 모든 데이터를 완벽히 분리
* 현실 데이터에서는 거의 불가능

### 소프트 마진

* 일부 오분류 허용
* **C 파라미터**로 허용 정도 조절

### C 파라미터의 의미

* C ↑

  * 오분류 허용 ↓
  * 과적합 위험 ↑
* C ↓

  * 마진 넓어짐
  * 과소적합 가능성 ↑

## 선형 SVM

### 특징

* 선형 결정 경계
* 고차원 데이터에 강함
* 로지스틱 회귀와 비교 대상

### 예제 

```python
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

pipe_svm_linear = Pipeline([
    ("scaler", StandardScaler()),
    ("model", SVC(kernel="linear", C=1.0))
])

pipe_svm_linear.fit(X_train, y_train)

pipe_svm_linear.score(X_test, y_test)
```

SVM은 **스케일링 필수**

## 비선형 SVM과 커널 트릭

현실 데이터는 선형으로 분리되지 않는 경우가 많다. 이때 사용하는 것이 **커널 함수(kernel)**이다.

### 커널 트릭 개념

* 원래 공간에서는 비선형
* 고차원 공간으로 변환하면 선형 분리 가능
* 실제로 변환을 계산하지 않고 **내적만 계산**

### 대표적인 커널

* Linear
* Polynomial
* RBF (Gaussian), 가장 많이 사용
* Sigmoid

##  RBF 커널과 γ (gamma)

### gamma의 의미

* 하나의 데이터가 미치는 영향 범위

### gamma 값의 영향

* gamma ↑

  * 영향 범위 좁음
  * 결정 경계 복잡
  * 과적합 위험 ↑
* gamma ↓

  * 영향 범위 넓음
  * 단순한 경계
  * 과소적합 가능성 ↑

### 예제 (RBF SVM)

```python
pipe_svm_rbf = Pipeline([
    ("scaler", StandardScaler()),
    ("model", SVC(
        kernel="rbf",
        C=1.0,
        gamma="scale"
    ))
])

pipe_svm_rbf.fit(X_train, y_train)

pipe_svm_rbf.score(X_test, y_test)
```

## 다중 분류에서의 SVM

SVM은 본래 **이진 분류 모델**이나 다중 클래스에서는 내부적으로 다음 방식을 사용한다.

* One-vs-Rest (OvR)
* One-vs-One (OvO, 기본값)

scikit-learn에서는 자동 처리된다.

## SVM의 장단점

### 장점

* 일반화 성능 우수
* 고차원 데이터에 강함
* 커널을 통한 강력한 비선형 표현

### 단점

* 대규모 데이터에서 학습 비용 큼
* 파라미터(C, gamma) 튜닝 필요
* 모델 해석 어려움

## 로지스틱 회귀 vs SVM

| 구분    | 로지스틱 회귀 | SVM    |
| ----- | ------- | ------ |
| 결정 기준 | 확률 최대화  | 마진 최대화 |
| 출력    | 확률      | 클래스    |
| 해석    | 쉬움      | 어려움    |
| 비선형   | 제한적     | 커널 사용  |

## 활용 가이드

* 데이터 수가 많지 않음
* 특성 차원이 높음
* 명확한 결정 경계 필요

이런 경우 **SVM은 매우 강력한 선택**

반면,

* 데이터가 매우 큼
* 모델 해석이 중요

트리 계열 또는 로지스틱 회귀 고려

