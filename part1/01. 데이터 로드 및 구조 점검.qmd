---
keywords:
  - pandas 데이터 로드
  - CSV 파일 읽기
  - Excel 파일 읽기
  - SQLite pandas
  - 데이터 구조 확인
  - 파이썬 데이터 분석 기초

description: >
  Python pandas를 활용해 CSV, Excel, SQLite 데이터베이스에서 데이터를 불러오고
  DataFrame의 구조와 데이터 타입, 결측값, 기술 통계량을 점검하는 데이터 분석의
  첫 단계를 설명한다.
---

# 데이터 로드 및 구조 점검

데이터 분석의 첫 단계는 데이터 수집이다. 데이터는 로컬 파일, 데이터베이스, 또는 외부 시스템에서 확보할 수 있으며, 형태는 상황에 따라 다양하다. 가장 일반적인 형태는 CSV와 Excel 파일이지만, API 호출이나 데이터베이스 쿼리를 통해 직접 취합하는 경우도 있다. 이 장에서는 다양한 소스로부터 데이터를 불러오는 방법과 불러온 데이터의 구조를 확인하는 방법을 학습한다.

```{python}
#| echo: false
#| output: false

import sys
sys.executable
```

## 데이터 로드

데이터를 분석하기 위해서는 먼저 파일이나 데이터베이스에 저장된 데이터를 메모리에 적재해야 한다. Python의 pandas 라이브러리는 다양한 형식의 데이터를 손쉽게 로드할 수 있는 함수를 제공한다. 여기서는 CSV, Excel, SQLite 데이터베이스 형태의 데이터를 불러오는 방법을 살펴본다.

예제에서는 남극 팔머 제도에 서식하는 펭귄 데이터를 담은 [`palmerpenguins`](https://pypi.org/project/palmerpenguins/) 데이터셋을 사용한다. 이 데이터셋은 펭귄의 종, 서식지, 신체 측정값 등의 정보를 포함하고 있다.

**예제: palmerpenguins 데이터셋 준비**

```{python}
#| warning: false
import pandas as pd
from palmerpenguins import load_penguins

# 데이터 로드
df = load_penguins()

# 데이터 미리보기
df.head()

# 다양한 형식으로 저장
df.to_csv("penguins.csv", index=False)        # CSV 파일로 저장
df.to_excel("penguins.xlsx", index=False)     # Excel 파일로 저장

# SQLite 데이터베이스에 저장
import sqlite3
conn = sqlite3.connect("penguins.db")
result = df.to_sql("penguins", conn, if_exists="replace", index=False)
conn.close()
```

### CSV 파일 로드

CSV(Comma-Separated Values)는 쉼표로 구분된 텍스트 파일 형식으로, 데이터 교환에 가장 널리 사용되는 형식이다. pandas의 `read_csv()` 함수를 사용하면 CSV 파일을 DataFrame 형태로 불러올 수 있다.

**예제: CSV 파일 불러오기**

```{python}
import pandas as pd

# CSV 파일 로드
df_from_csv = pd.read_csv("penguins.csv")

# 상위 5개 행 확인
df_from_csv.head()
```

### Excel 파일 로드

Excel 파일(.xlsx, .xls)은 비즈니스 환경에서 자주 사용되는 형식이다. pandas의 `read_excel()` 함수를 사용하면 Excel 파일을 불러올 수 있으며, 특정 시트를 지정하여 읽을 수도 있다.

**예제: Excel 파일 불러오기**

```{python}
import pandas as pd

# Excel 파일 로드
df_from_excel = pd.read_excel("penguins.xlsx")

# 상위 5개 행 확인
df_from_excel.head()
```

### SQLite 데이터베이스 로드

데이터베이스는 대량의 데이터를 체계적으로 관리하는 시스템이다. SQLite는 파일 기반의 경량 데이터베이스로, 별도의 서버 설치 없이 사용할 수 있다. pandas의 `read_sql()` 함수를 사용하면 SQL 쿼리 결과를 DataFrame으로 불러올 수 있다.

**예제: SQLite 데이터베이스에서 데이터 불러오기**

```{python}
import sqlite3
import pandas as pd

# 데이터베이스 연결
conn = sqlite3.connect("penguins.db")

# SQL 쿼리 실행 및 결과 로드
query = "SELECT * FROM penguins"
df_from_sql = pd.read_sql(query, conn)

# 연결 종료
conn.close()

# 상위 5개 행 확인
df_from_sql.head()
```

## 데이터 구조 및 타입 확인

데이터를 성공적으로 불러온 후에는 데이터의 전반적인 구조를 파악해야 한다. 데이터의 크기(행과 열의 개수), 각 컬럼의 이름과 데이터 타입, 결측값 유무 등을 확인하는 것이 데이터 분석의 기본이다. 이러한 정보는 후속 분석 방향을 결정하고 데이터 전처리 계획을 수립하는 데 필수적이다.

### 데이터 크기 확인

DataFrame의 크기는 `shape` 속성을 통해 확인할 수 있다. `shape`는 (행의 개수, 열의 개수) 형태의 튜플을 반환한다.

**예제: 데이터 크기 확인**

```{python}
import pandas as pd

df = pd.read_csv("penguins.csv")

# 데이터 크기 확인 (행, 열)
df.shape
```

### 데이터 기본 정보 확인

`info()` 메서드는 DataFrame의 전반적인 정보를 요약하여 보여준다. 각 컬럼의 데이터 타입, 결측값이 아닌 데이터의 개수, 메모리 사용량 등을 한눈에 파악할 수 있다.

**예제: 데이터 기본 정보 확인**

```{python}
# 데이터 구조 및 타입 정보
df.info()
```

위 코드를 실행하면 다음과 같은 정보를 확인할 수 있다.

| 정보 항목 | 설명 |
|---------|------|
| RangeIndex | 전체 행의 개수 |
| Data columns | 컬럼의 개수 |
| Column | 각 컬럼의 이름 |
| Non-Null Count | 결측값이 아닌 데이터의 개수 |
| Dtype | 각 컬럼의 데이터 타입 (int64, float64, object 등) |
| memory usage | DataFrame이 사용하는 메모리 크기 |

### 컬럼별 데이터 타입 확인

각 컬럼의 데이터 타입만 간단히 확인하고 싶을 때는 `dtypes` 속성을 사용한다.

**예제: 컬럼별 데이터 타입 확인**

```{python}
# 각 컬럼의 데이터 타입
df.dtypes
```

### 기술 통계량 확인

수치형 데이터의 기본적인 통계량(평균, 표준편차, 최솟값, 최댓값 등)은 `describe()` 메서드로 확인할 수 있다.

**예제: 기술 통계량 확인**

```{python}
# 수치형 컬럼의 기술 통계량
df.describe()
```

## 요약

이 장에서는 데이터 분석의 첫 단계인 데이터 로드와 구조 점검 방법을 학습했다. 주요 내용은 다음과 같다.

**데이터 로드**  

- CSV 파일: `pd.read_csv()` 함수 사용  
- Excel 파일: `pd.read_excel()` 함수 사용  
- SQLite 데이터베이스: `pd.read_sql()` 함수 사용  

**데이터 구조 확인**  

- `shape`: 데이터의 크기(행, 열) 확인  
- `info()`: 컬럼명, 데이터 타입, 결측값 개수, 메모리 사용량 확인  
- `dtypes`: 각 컬럼의 데이터 타입 확인  
- `describe()`: 수치형 데이터의 기술 통계량 확인  

데이터를 정확하게 불러오고 그 구조를 이해하는 것은 모든 데이터 분석 작업의 기반이다. 다음 장에서는 데이터 특성과 패턴을 파악하는 탐색적 데이터 분석(EDA)을 학습할 것이다.
