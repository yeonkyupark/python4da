[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "파이썬 데이터 분석",
    "section": "",
    "text": "들어가기\n기계학습으로 데이터를 분석한다. 분석 도구는 파이썬으로 데이터 전처리, 통계 분석, 기계학습 모델링 및 평가까지 코드 중심으로 구성된다. 실무에 필요한 내용을 정리하여 이론적, 학문적으로 미흡한 부분이 있다. 부족한 부분은 향후 성능 개선과 향상된 알고리즘 등으로 수정키로 한다.\n파이썬 버전은 3.12 기반으로 numpy, pandas, sklearn, scipy, stats와 같은 기본적인 라이브러리를 사용한다.\n전체 목차는 다음과 같다.",
    "crumbs": [
      "들어가기"
    ]
  },
  {
    "objectID": "index.html#부.-데이터-전처리-분포-이해",
    "href": "index.html#부.-데이터-전처리-분포-이해",
    "title": "파이썬 데이터 분석",
    "section": "1부. 데이터 전처리 & 분포 이해",
    "text": "1부. 데이터 전처리 & 분포 이해\n\n1.1 데이터 로드 및 구조 점검\n\n데이터 로드 (CSV, Excel, SQL)\n데이터 구조 및 타입 확인\n\n\n\n1.2 탐색적 데이터 분석(EDA)\n\n기술통계량 요약\n분포 시각화 (히스토그램, KDE, 박스플롯)\n상관관계 탐색\n\n\n\n1.3 데이터 분포 이해\n\n연속형·이산형 데이터 분포\n왜도와 첨도\n분포 해석을 통한 전처리 전략\n\n\n\n1.4 결측치 처리\n\n결측치 탐지 및 요약\n단순 대치 기법\n고급 대치 기법 (KNN, Iterative)\n\n\n\n1.5 이상치 탐지\n\n정규분포 기반 이상치\nIQR 기반 이상치\n밀도 기반 이상치 (LOF, DBSCAN)\n트리 기반 이상치 (IsolationForest)\n\n\n\n1.6 스케일링\n\n정규화 (Min-Max)\n표준화 (Standard, Robust, MaxAbs)\n\n\n\n1.7 데이터 분포 변환\n\n로그 변환\nBox-Cox 변환\nYeo-Johnson 변환\n분위수 변환\n변환 전·후 분포 비교\n\n\n\n1.8 범주형 데이터 처리\n\n명목형 인코딩\n순서형 인코딩\n\n\n\n1.9 연속형 데이터 범주화\n\n구간 분할 (cut, qcut, KBins)\n\n\n\n1.10 불균형 데이터 처리\n\n오버샘플링\n언더샘플링\n\n\n\n1.11 피처 엔지니어링\n\n다항 특성 생성\n집계 및 롤링 특성",
    "crumbs": [
      "들어가기"
    ]
  },
  {
    "objectID": "index.html#부.-통계-기반-데이터-분석-가설검정",
    "href": "index.html#부.-통계-기반-데이터-분석-가설검정",
    "title": "파이썬 데이터 분석",
    "section": "2부. 통계 기반 데이터 분석 & 가설검정",
    "text": "2부. 통계 기반 데이터 분석 & 가설검정\n\n2.1 확률분포와 표본\n\n연속형 확률분포\n이산형 확률분포\n표본 분포 개념\n\n\n\n2.2 정규성 검정\n\nShapiro-Wilk 검정\nKolmogorov-Smirnov 검정\nAnderson-Darling 검정\nQ-Q plot 해석\n\n\n\n2.3 등분산성 검정\n\nLevene 검정\nBartlett 검정\nFligner-Killeen 검정\n\n\n\n2.4 적합성 검정 & 독립성 검정\n\n카이제곱 적합성 검정\n분포 적합성 검정\n카이제곱 독립성 검정\nF 검정 (분산 비교)\n\n\n\n2.5 평균 비교 검정\n\n단일 표본 t-검정\n독립 표본 t-검정\n대응 표본 t-검정\n\n\n\n2.6 분산분석\n\n일원 분산 분석 (One-way ANOVA)\n이원 분산 분석 (Two-way ANOVA)\n사후 검정\n\n\n\n2.7 비모수 검정\n\nMann-Whitney U 검정\nWilcoxon 순위합 검정\nKruskal-Wallis 검정\nFriedman 검정\n\n\n\n2.8 상관 분석\n\nPearson 상관 분석\nSpearman 순위 상관",
    "crumbs": [
      "들어가기"
    ]
  },
  {
    "objectID": "index.html#부.-머신러닝-모델링-평가",
    "href": "index.html#부.-머신러닝-모델링-평가",
    "title": "파이썬 데이터 분석",
    "section": "3부. 머신러닝 모델링 & 평가",
    "text": "3부. 머신러닝 모델링 & 평가\n\n3.1 데이터 분할 및 검증\n\n학습·검증·테스트 분할\n교차 검증 기법\n\n\n\n3.2 특성 선택\n\n필터 방법\n래퍼 방법\n임베디드 방법\n\n\n\n3.3 차원 축소\n\n선형 차원 축소 (PCA)\n비선형 차원 축소 (t-SNE, UMAP)\n\n\n\n3.4 회귀 모델\n\n선형 회귀\n정규화 회귀 (Ridge, Lasso, ElasticNet)\n\n\n\n3.5 분류 모델\n\n선형 분류 모델\n거리 기반 모델\n트리 및 앙상블 모델\n\n\n\n3.6 서포트 벡터 머신\n\nSVM 분류\n\n\n\n3.7 군집 분석\n\n분할 기반 군집\n밀도 기반 군집\n혼합 모델 군집\n\n\n\n3.8 모델 성능 평가\n\n분류 성능 평가\n회귀 성능 평가\n\n\n\n3.9 파이프라인 & 자동화\n\n파이프라인 구성\n하이퍼파라미터 최적화\n\n\n\n3.10 모델 해석\n\n특성 중요도\nSHAP 기반 모델 해석",
    "crumbs": [
      "들어가기"
    ]
  },
  {
    "objectID": "part1/01. 데이터 로드 및 구조 점검.html",
    "href": "part1/01. 데이터 로드 및 구조 점검.html",
    "title": "1  데이터 로드 및 구조 점검",
    "section": "",
    "text": "1.1 데이터 로드\n데이터 분석에 있어 가장 먼저 하는 작업이 데이터를 수집하는 것이다. 데이터 수집 방법에는 여러 가지가 있을 수 있고 대부분 로컬 파일이나 데이터베이스 또는 다른 시스템의 산출물에서 확보한다. 또한 데이터 원천에서 수집되는 데이터 형태는 시스템이나 상황에 따라 다양할 수 있지만 일반적으로 CSV나 Excel 형태로 처리하게 된다. 물론 API나 데이터베이스에 직접 Query해서 취합할 수도 있다.\n가장 일반적인 자료 형태인 CSV 파일과 Excel 파일을 메모리에 적재하는 방법을 알아 본다. 아래는 예제로 사용할 palmerpenguins 데이터셋이다.\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\ndf = load_penguins()\n\ndf.head()\n\ndf.to_csv(\"penguins.csv\", index=False) # CSV 파일로 저장\ndf.to_excel(\"./penguins.xlsx\", index=False) # Excel 파일로 저장\n\n# sqlite DB\nimport sqlite3\nconn = sqlite3.connect(\"penguins.db\")\nresult = df.to_sql(\"penguins\", conn, if_exists=\"replace\", index=False)",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 로드 및 구조 점검</span>"
    ]
  },
  {
    "objectID": "part1/01. 데이터 로드 및 구조 점검.html#데이터-로드",
    "href": "part1/01. 데이터 로드 및 구조 점검.html#데이터-로드",
    "title": "1  데이터 로드 및 구조 점검",
    "section": "",
    "text": "1.1.1 CSV 파일 로드\n\nimport pandas as pd\n\ndf_from_csv = pd.read_csv(\"penguins.csv\")\n\ndf_from_csv.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n1.1.2 Excel 파일 로드\n\nimport pandas as pd\n\ndf_from_excel = pd.read_excel(\"penguins.xlsx\")\n\ndf_from_excel.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n1.1.3 SQLite 데이터베이스 로드\n\nimport sqlite3\n\nconn = sqlite3.connect(\"penguins.db\")\n\nquery = \"SELECT * FROM penguins\"\ndf_from_sql = pd.read_sql(query, conn)\n\ndf_from_sql.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 로드 및 구조 점검</span>"
    ]
  },
  {
    "objectID": "part1/01. 데이터 로드 및 구조 점검.html#데이터-구조-및-타입-확인",
    "href": "part1/01. 데이터 로드 및 구조 점검.html#데이터-구조-및-타입-확인",
    "title": "1  데이터 로드 및 구조 점검",
    "section": "1.2 데이터 구조 및 타입 확인",
    "text": "1.2 데이터 구조 및 타입 확인\n수집된 데이터에서 가장 먼저 확인하는 것은 데이터의 크기와 컬럼에 대한 정보이다.\n\n1.2.1 데이터 크기와 기본 정보\n\nimport pandas as pd\n\ndf = pd.read_csv(\"penguins.csv\")\n\ndf.shape\n\n(344, 8)\n\n\n\ndf.info()\n\n&lt;class 'pandas.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    str    \n 1   island             344 non-null    str    \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    str    \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), str(3)\nmemory usage: 21.6 KB",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 로드 및 구조 점검</span>"
    ]
  },
  {
    "objectID": "part1/02. 탐색적 데이터 분석(EDA).html",
    "href": "part1/02. 탐색적 데이터 분석(EDA).html",
    "title": "2  탐색적 데이터 분석(EDA)",
    "section": "",
    "text": "2.1 라이브러리 로드 & 데이터 불러오기\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# seaborn 내장 penguins 데이터셋 로드\ndf = sns.load_dataset(\"penguins\")\n\ndf.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nMale\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nFemale\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nFemale\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nFemale",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>탐색적 데이터 분석(EDA)</span>"
    ]
  },
  {
    "objectID": "part1/02. 탐색적 데이터 분석(EDA).html#데이터-구조-확인",
    "href": "part1/02. 탐색적 데이터 분석(EDA).html#데이터-구조-확인",
    "title": "2  탐색적 데이터 분석(EDA)",
    "section": "2.2 데이터 구조 확인",
    "text": "2.2 데이터 구조 확인\n\ndf.shape\n\n(344, 7)\n\n\n\ndf.info()\n\n&lt;class 'pandas.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    str    \n 1   island             344 non-null    str    \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    str    \ndtypes: float64(4), str(3)\nmemory usage: 18.9 KB\n\n\n확인 포인트\n\n행(row), 열(column) 개수\n변수 타입 (수치형 / 범주형)\n결측치 여부",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>탐색적 데이터 분석(EDA)</span>"
    ]
  },
  {
    "objectID": "part1/02. 탐색적 데이터 분석(EDA).html#기초-통계량-확인",
    "href": "part1/02. 탐색적 데이터 분석(EDA).html#기초-통계량-확인",
    "title": "2  탐색적 데이터 분석(EDA)",
    "section": "2.3 기초 통계량 확인",
    "text": "2.3 기초 통계량 확인\n\n2.3.1 수치형 변수 요약\n\ndf.describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n\n\n\n\n\n\n\n\n\n2.3.2 범주형 변수 요약\n\ndf.describe(include=\"object\")\n\n\n\n\n\n\n\n\nspecies\nisland\nsex\n\n\n\n\ncount\n344\n344\n333\n\n\nunique\n3\n3\n2\n\n\ntop\nAdelie\nBiscoe\nMale\n\n\nfreq\n152\n168\n168",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>탐색적 데이터 분석(EDA)</span>"
    ]
  },
  {
    "objectID": "part1/02. 탐색적 데이터 분석(EDA).html#결측치-탐색",
    "href": "part1/02. 탐색적 데이터 분석(EDA).html#결측치-탐색",
    "title": "2  탐색적 데이터 분석(EDA)",
    "section": "2.4 결측치 탐색",
    "text": "2.4 결측치 탐색\n\ndf.isna().sum()\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\ndtype: int64\n\n\n\n(df.isna().mean() * 100).round(1)\n\nspecies              0.0\nisland               0.0\nbill_length_mm       0.6\nbill_depth_mm        0.6\nflipper_length_mm    0.6\nbody_mass_g          0.6\nsex                  3.2\ndtype: float64",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>탐색적 데이터 분석(EDA)</span>"
    ]
  },
  {
    "objectID": "part1/02. 탐색적 데이터 분석(EDA).html#범주형-변수-탐색",
    "href": "part1/02. 탐색적 데이터 분석(EDA).html#범주형-변수-탐색",
    "title": "2  탐색적 데이터 분석(EDA)",
    "section": "2.5 범주형 변수 탐색",
    "text": "2.5 범주형 변수 탐색\n\n2.5.1 종(species) 분포\n\ndf[\"species\"].value_counts()\n\nspecies\nAdelie       152\nGentoo       124\nChinstrap     68\nName: count, dtype: int64\n\n\n\nsns.countplot(data=df, x=\"species\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2.5.2 성별(sex) 분포\n\nsns.countplot(data=df, x=\"sex\")\nplt.show()",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>탐색적 데이터 분석(EDA)</span>"
    ]
  },
  {
    "objectID": "part1/02. 탐색적 데이터 분석(EDA).html#수치형-변수-분포-확인",
    "href": "part1/02. 탐색적 데이터 분석(EDA).html#수치형-변수-분포-확인",
    "title": "2  탐색적 데이터 분석(EDA)",
    "section": "2.6 수치형 변수 분포 확인",
    "text": "2.6 수치형 변수 분포 확인\n\n2.6.1 히스토그램\n\ndf.hist(bins=20, figsize=(10, 8))\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2.6.2 박스플롯 (이상치 탐색)\n\nplt.figure(figsize=(8, 4))\nsns.boxplot(data=df, x=\"species\", y=\"body_mass_g\")\nplt.show()",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>탐색적 데이터 분석(EDA)</span>"
    ]
  },
  {
    "objectID": "part1/02. 탐색적 데이터 분석(EDA).html#변수-간-관계-탐색",
    "href": "part1/02. 탐색적 데이터 분석(EDA).html#변수-간-관계-탐색",
    "title": "2  탐색적 데이터 분석(EDA)",
    "section": "2.7 변수 간 관계 탐색",
    "text": "2.7 변수 간 관계 탐색\n\n2.7.1 두 수치형 변수 관계\n\nsns.scatterplot(\n    data=df,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    hue=\"species\"\n)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2.7.2 페어플롯\n\nsns.pairplot(\n    df,\n    hue=\"species\",\n    diag_kind=\"hist\"\n)\nplt.show()",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>탐색적 데이터 분석(EDA)</span>"
    ]
  },
  {
    "objectID": "part1/02. 탐색적 데이터 분석(EDA).html#그룹별-통계-확인",
    "href": "part1/02. 탐색적 데이터 분석(EDA).html#그룹별-통계-확인",
    "title": "2  탐색적 데이터 분석(EDA)",
    "section": "2.8 그룹별 통계 확인",
    "text": "2.8 그룹별 통계 확인\n\ndf.groupby(\"species\")[[\"bill_length_mm\", \"body_mass_g\"]].mean()\n\n\n\n\n\n\n\n\nbill_length_mm\nbody_mass_g\n\n\nspecies\n\n\n\n\n\n\nAdelie\n38.791391\n3700.662252\n\n\nChinstrap\n48.833824\n3733.088235\n\n\nGentoo\n47.504878\n5076.016260",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>탐색적 데이터 분석(EDA)</span>"
    ]
  },
  {
    "objectID": "part1/02. 탐색적 데이터 분석(EDA).html#간단한-eda-결론-예시",
    "href": "part1/02. 탐색적 데이터 분석(EDA).html#간단한-eda-결론-예시",
    "title": "2  탐색적 데이터 분석(EDA)",
    "section": "2.9 간단한 EDA 결론 예시",
    "text": "2.9 간단한 EDA 결론 예시\n\n종(species)에 따라 부리 길이와 몸무게 분포가 뚜렷하게 구분된다.\nAdelie 종은 상대적으로 몸무게와 부리 길이가 작다.\n일부 변수에 결측치가 존재하므로 분석 전 처리 전략이 필요하다.",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>탐색적 데이터 분석(EDA)</span>"
    ]
  },
  {
    "objectID": "part1/02. 탐색적 데이터 분석(EDA).html#eda-기본-흐름-요약",
    "href": "part1/02. 탐색적 데이터 분석(EDA).html#eda-기본-흐름-요약",
    "title": "2  탐색적 데이터 분석(EDA)",
    "section": "2.10 EDA 기본 흐름 요약",
    "text": "2.10 EDA 기본 흐름 요약\n\n데이터 구조 확인 → info(), shape\n기초 통계 → describe()\n결측치 → isna()\n분포 → 히스토그램, 박스플롯\n관계 → 산점도, pairplot\n그룹 비교 → groupby()",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>탐색적 데이터 분석(EDA)</span>"
    ]
  },
  {
    "objectID": "part1/03. 결측치 처리.html",
    "href": "part1/03. 결측치 처리.html",
    "title": "3  결측치 처리",
    "section": "",
    "text": "3.1 데이터 로드 & 결측치 현황 재확인\nimport pandas as pd\nimport seaborn as sns\n\ndf = sns.load_dataset(\"penguins\")\n\ndf.isna().sum()\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\ndtype: int64",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>결측치 처리</span>"
    ]
  },
  {
    "objectID": "part1/03. 결측치 처리.html#결측치-비율-확인",
    "href": "part1/03. 결측치 처리.html#결측치-비율-확인",
    "title": "3  결측치 처리",
    "section": "3.2 결측치 비율 확인",
    "text": "3.2 결측치 비율 확인\n\n(df.isna().mean() * 100).round(1)\n\nspecies              0.0\nisland               0.0\nbill_length_mm       0.6\nbill_depth_mm        0.6\nflipper_length_mm    0.6\nbody_mass_g          0.6\nsex                  3.2\ndtype: float64",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>결측치 처리</span>"
    ]
  },
  {
    "objectID": "part1/03. 결측치 처리.html#결측치-제거-행-삭제",
    "href": "part1/03. 결측치 처리.html#결측치-제거-행-삭제",
    "title": "3  결측치 처리",
    "section": "3.3 결측치 제거 (행 삭제)",
    "text": "3.3 결측치 제거 (행 삭제)\n\n3.3.1 전체 결측치가 있는 행 제거\n\ndf_drop_all = df.dropna()\ndf_drop_all.shape\n\n(333, 7)\n\n\n\n\n3.3.2 결측치가 3개 이상인 행 제거\n\ndf[\"na_count\"] = df.isna().sum(axis=1)\ndf_row_filtered = df[df[\"na_count\"] &lt; 3].drop(columns=\"na_count\")\ndf_row_filtered.shape\n\n(342, 7)\n\n\n\n# 결측치가 전체 컬럼에서 2개까지만 허용()\ndf_thresh = df.dropna(thresh=len(df.columns)-2)\n\n\n\n3.3.3 특정 컬럼 기준 제거\n\ndf_drop_sex = df.dropna(subset=[\"sex\"])",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>결측치 처리</span>"
    ]
  },
  {
    "objectID": "part1/03. 결측치 처리.html#수치형-변수-결측치-대체",
    "href": "part1/03. 결측치 처리.html#수치형-변수-결측치-대체",
    "title": "3  결측치 처리",
    "section": "3.4 수치형 변수 결측치 대체",
    "text": "3.4 수치형 변수 결측치 대체\n\n3.4.1 평균(mean) 대체\n특정 컬럼에 대한 평균 대체\n\ndf_mean = df.copy()\ndf_mean[\"bill_length_mm\"] = df_mean[\"bill_length_mm\"].fillna(\n    df_mean[\"bill_length_mm\"].mean()\n)\n\n다중 컬럼에 대한 처리 - 1\n\ndf_cols = df.copy()\nnum_cols = [\n    \"bill_length_mm\",\n    \"bill_depth_mm\",\n    \"flipper_length_mm\",\n    \"body_mass_g\"\n]\n\n\ndf_cols[num_cols] = df_cols[num_cols].fillna(df[num_cols].mean())\n\n다중 컬럼에 대한 처리 - 2\n\nfor col in num_cols:\n    mean_value = df[col].mean()\n    df[col] = df[col].fillna(mean_value)\n\n범주별 다중 컬럼 처리\n\ndf_group = df.copy()\n\ndf_group[num_cols] = df_group[num_cols].fillna(\n    df_group.groupby(\"species\")[num_cols].transform(\"mean\")\n)\n\n\n\n3.4.2 중앙값(median) 대체\n\ndf_median = df.copy()\ndf_median[\"bill_depth_mm\"] = df_median[\"bill_depth_mm\"].fillna(\n    df_median[\"bill_depth_mm\"].median()\n)",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>결측치 처리</span>"
    ]
  },
  {
    "objectID": "part1/03. 결측치 처리.html#범주형-변수-결측치-대체",
    "href": "part1/03. 결측치 처리.html#범주형-변수-결측치-대체",
    "title": "3  결측치 처리",
    "section": "3.5 범주형 변수 결측치 대체",
    "text": "3.5 범주형 변수 결측치 대체\n\n3.5.1 최빈값(mode) 대체\n\ndf_mode = df.copy()\nmode_sex = df_mode[\"sex\"].mode()[0]\ndf_mode[\"sex\"] = df_mode[\"sex\"].fillna(mode_sex)\n\n\n\n3.5.2 명시적 범주 추가\n\ndf_category = df.copy()\ndf_category[\"sex\"] = df_category[\"sex\"].fillna(\"Unknown\")\n\n\ndf_mode = df.copy()\n\ncat_cols = [\"sex\", \"island\"]\n\nfor col in cat_cols:\n    mode_value = df_mode[col].mode()[0]\n    df_mode[col] = df_mode[col].fillna(mode_value)\n\n\ndf_mode = df.copy()\n\ndf_mode[\"sex\"] = df_mode[\"sex\"].fillna(\n    df_mode.groupby(\"species\")[\"sex\"].transform(\n        lambda x: x.mode()[0]\n    )\n)\n\n\ndf_mode = df.copy()\n\ncat_cols = [\"sex\", \"island\"]\n\nfor col in cat_cols:\n    df_mode[col] = df_mode[col].fillna(\n        df_mode.groupby(\"species\")[col].transform(\n            lambda x: x.mode()[0]\n        )\n    )",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>결측치 처리</span>"
    ]
  },
  {
    "objectID": "part1/03. 결측치 처리.html#결측치-처리-후-검증",
    "href": "part1/03. 결측치 처리.html#결측치-처리-후-검증",
    "title": "3  결측치 처리",
    "section": "3.6 결측치 처리 후 검증",
    "text": "3.6 결측치 처리 후 검증\n\ndf_group.isna().sum()\n\nspecies               0\nisland                0\nbill_length_mm        0\nbill_depth_mm         0\nflipper_length_mm     0\nbody_mass_g           0\nsex                  11\nna_count              0\ndtype: int64\n\n\n\ndf_group.info()\n\n&lt;class 'pandas.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    str    \n 1   island             344 non-null    str    \n 2   bill_length_mm     344 non-null    float64\n 3   bill_depth_mm      344 non-null    float64\n 4   flipper_length_mm  344 non-null    float64\n 5   body_mass_g        344 non-null    float64\n 6   sex                333 non-null    str    \n 7   na_count           344 non-null    int64  \ndtypes: float64(4), int64(1), str(3)\nmemory usage: 21.6 KB",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>결측치 처리</span>"
    ]
  },
  {
    "objectID": "part1/03. 결측치 처리.html#결측치-처리-권장-순서",
    "href": "part1/03. 결측치 처리.html#결측치-처리-권장-순서",
    "title": "3  결측치 처리",
    "section": "3.7 결측치 처리 권장 순서",
    "text": "3.7 결측치 처리 권장 순서\n\n결측치 현황 파악\n제거 가능한 행/열 판단\n수치형 → 그룹 기반 대체\n범주형 → mode 또는 Unknown\n최종 검증",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>결측치 처리</span>"
    ]
  },
  {
    "objectID": "part1/04. 이상치 탐지.html",
    "href": "part1/04. 이상치 탐지.html",
    "title": "4  이상치 탐지",
    "section": "",
    "text": "4.1 분포 기반 이상치 탐지\n분석 대상은 수치형 변수만 사용",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>이상치 탐지</span>"
    ]
  },
  {
    "objectID": "part1/04. 이상치 탐지.html#분포-기반-이상치-탐지",
    "href": "part1/04. 이상치 탐지.html#분포-기반-이상치-탐지",
    "title": "4  이상치 탐지",
    "section": "",
    "text": "4.1.1 박스플롯으로 이상치 확인\n\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\n\ndf_num_scaled = pd.DataFrame(scale.fit_transform(df_num[num_cols]),\n                              columns=df_num.columns)\n\ndf_num_scaled.boxplot(figsize=(10, 5))\nplt.show()",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>이상치 탐지</span>"
    ]
  },
  {
    "objectID": "part1/04. 이상치 탐지.html#iqr-기반-이상치-탐지",
    "href": "part1/04. 이상치 탐지.html#iqr-기반-이상치-탐지",
    "title": "4  이상치 탐지",
    "section": "4.2 IQR 기반 이상치 탐지",
    "text": "4.2 IQR 기반 이상치 탐지\n\n4.2.1 IQR 계산\n\nQ1 = df_num.quantile(0.25)\nQ3 = df_num.quantile(0.75)\nIQR = Q3 - Q1\n\n\n\n4.2.2 이상치 조건 정의\n\noutlier_condition = (df_num &lt; (Q1 - 1.5 * IQR)) | (df_num &gt; (Q3 + 1.5 * IQR))\n\n\n\n4.2.3 이상치가 있는 행 확인\n\noutlier_rows = outlier_condition.any(axis=1)\ndf[outlier_rows]\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n\n\n\n\n\n컬럼 중 하나라도 이상치면 해당 행 전체를 이상치로 판단\n\n\n4.2.4 이상치 제거\n\ndf_iqr_clean = df[~outlier_rows]",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>이상치 탐지</span>"
    ]
  },
  {
    "objectID": "part1/04. 이상치 탐지.html#z-score-기반-이상치-탐지",
    "href": "part1/04. 이상치 탐지.html#z-score-기반-이상치-탐지",
    "title": "4  이상치 탐지",
    "section": "4.3 Z-score 기반 이상치 탐지",
    "text": "4.3 Z-score 기반 이상치 탐지\n\nfrom scipy.stats import zscore\n\n\nz_scores = df_num.apply(zscore)\n\n\n4.3.1 임계값 기준 이상치 탐지 (|z| &gt; 3)\n\noutlier_z = (np.abs(z_scores) &gt; 3).any(axis=1)\ndf_z_clean = df[~outlier_z]\n\n계산이 간단한 장점이 있으나 분포 왜곡에 취약한 단점 존재",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>이상치 탐지</span>"
    ]
  },
  {
    "objectID": "part1/04. 이상치 탐지.html#범주별-이상치-탐지",
    "href": "part1/04. 이상치 탐지.html#범주별-이상치-탐지",
    "title": "4  이상치 탐지",
    "section": "4.4 범주별 이상치 탐지",
    "text": "4.4 범주별 이상치 탐지\n\n4.4.1 species별 IQR 이상치 탐지\n\ndef iqr_outlier_by_group(group):\n    Q1 = group[num_cols].quantile(0.25)\n    Q3 = group[num_cols].quantile(0.75)\n    IQR = Q3 - Q1\n\n    condition = (group[num_cols] &lt; (Q1 - 1.5 * IQR)) | \\\n                (group[num_cols] &gt; (Q3 + 1.5 * IQR))\n    return group[~condition.any(axis=1)]\n\n\ndf_group_iqr_clean = (\n    df.groupby(\"species\", group_keys=False)\n      .apply(iqr_outlier_by_group)\n)",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>이상치 탐지</span>"
    ]
  },
  {
    "objectID": "part1/04. 이상치 탐지.html#밀도-기반-이상치-탐지-lof",
    "href": "part1/04. 이상치 탐지.html#밀도-기반-이상치-탐지-lof",
    "title": "4  이상치 탐지",
    "section": "4.5 밀도 기반 이상치 탐지 (LOF)",
    "text": "4.5 밀도 기반 이상치 탐지 (LOF)\n\nfrom sklearn.neighbors import LocalOutlierFactor\n\n\ndf_lof = df_num.dropna()\n\nlof = LocalOutlierFactor(n_neighbors=20)\noutlier_lof = lof.fit_predict(df_lof)\n\n\ndf_lof_clean = df.loc[df_lof.index][outlier_lof == 1]\n\n주변 데이터와 너무 다른 밀도를 가지면 이상치로 판단하는 방식으로 비선형 데이터에 강함",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>이상치 탐지</span>"
    ]
  },
  {
    "objectID": "part1/04. 이상치 탐지.html#트리-기반-이상치-탐지-isolation-forest",
    "href": "part1/04. 이상치 탐지.html#트리-기반-이상치-탐지-isolation-forest",
    "title": "4  이상치 탐지",
    "section": "4.6 트리 기반 이상치 탐지 (Isolation Forest)",
    "text": "4.6 트리 기반 이상치 탐지 (Isolation Forest)\n\nfrom sklearn.ensemble import IsolationForest\n\n\niso = IsolationForest(contamination=0.05, random_state=42)\noutlier_if = iso.fit_predict(df_lof)\n\n\ndf_if_clean = df.loc[df_lof.index][outlier_if == 1]\n\n이상치는 트리 분류 기준으로 쉽게 분리가 된다는 가정하에 이상치를 탐지하는 방식으로 고차원 데이터에 강함하고 실무에서 자주 사용",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>이상치 탐지</span>"
    ]
  },
  {
    "objectID": "part1/04. 이상치 탐지.html#단계별-선택-가이드",
    "href": "part1/04. 이상치 탐지.html#단계별-선택-가이드",
    "title": "4  이상치 탐지",
    "section": "4.7 단계별 선택 가이드",
    "text": "4.7 단계별 선택 가이드\n\n\n\n단계\n방법\n언제 쓰나\n\n\n\n\n1\n시각화\n이해, 설명\n\n\n2\nIQR\n기본, 안전\n\n\n3\nZ-score\n정규분포 가정\n\n\n4\n그룹별 IQR\n가장 실무적\n\n\n5\nLOF\n비선형, 밀도\n\n\n6\nIsolationForest\n대규모, 고급",
    "crumbs": [
      "Ⅰ. 데이터 전처리 및 변환",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>이상치 탐지</span>"
    ]
  }
]